{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b00afd9",
   "metadata": {},
   "source": [
    "## Feature engineering \n",
    "- feature engineering is the process of using domain knowledge to extract features from raw data. These features can used to improve the performance of machine learning algorithms\n",
    "\n",
    "- if you give clean and better feature to bad algorithm its gives good result\n",
    "- if you give not better data to good algorithm its gives bad result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28755525",
   "metadata": {},
   "source": [
    "fourt part\n",
    "- feature transformation - missing valus imputation,Handling categorical feature- OneHotEncoding, outlier detection-important to remove outlier ,feature scaling - feature scaling means if numerical column values are more different then scaling is important,types - min-max scaling, standardization,normalizatin, absolute scaling, log transform\n",
    "- feature construction- creating feature using domain knowledge, in titanic dataset siblingpouse and parentchild altho family so we can add them and create new column family member or also you can transform into category like 0 means alone 0-4 means small\n",
    "- feature selection - most important feature select , extra non meaning featue are impact your result, and slow down the model\n",
    "- feature extraction - in real istate dataset there are two column no of rooms and no of washroom you need to take one column then you need to add both columns overall both columns increase square fit of area. when you dealing with highdimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db30b8",
   "metadata": {},
   "source": [
    "### Feature scaling - is the technique to standardize the independent feature present in the data in a fixed range\n",
    "### types\n",
    "- Standardization\n",
    "- Normalization - min-max scalar, roubars scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46ec4f",
   "metadata": {},
   "source": [
    "### Standardization - mean centering and standard deviation is 1\n",
    "- always do train test split before standardization\n",
    "age    salary\n",
    "27     120000\n",
    "23     145000\n",
    "34     100000\n",
    "22     134000\n",
    "\n",
    "newcol-age  xi = 27-mean(28)/10 std\n",
    "farmila--> value - mean / std\n",
    "u(mew)=o,sigma(std)=1\n",
    "\n",
    "The Standardized Values Formula\n",
    "If you’re asked to find standardized values, use this formula to make your calculations:\n",
    "Standardized Values: Example\n",
    "\n",
    "You calculate a standardized value (a z-score), using the above formula. The symbols are:\n",
    "\n",
    "X: the observation (a specific value that you are calculating the z-score for).\n",
    "Mu(μ): the mean.\n",
    "Sigma(σ): the standard deviation.\n",
    "These values are always given in the question.\n",
    "\n",
    "#### Impact of outliers\n",
    "- no impact on outliers of scaling u need to handle its manually\n",
    "- with outliers prediction accuracy less while after removing outliers accuracy increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb0635",
   "metadata": {},
   "source": [
    "- in Logistic regression classifier algorithm always gives scalling data it gives 20-30 percent more accuracy than unscaled data\n",
    "- but in desicionTreeClassifier scaling and without scaling same result, no impact scaling on this algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6a2ed",
   "metadata": {},
   "source": [
    "### when to apply standardization - scaling\n",
    "- when u work on algorithm \n",
    "1. k-means -use euclidean distance measure\n",
    "2. knn - measures the distance between pairs of sample and these distances are influenced by the measurement units\n",
    "3. Principal components analysis - try to get feature with maximum variance\n",
    "4. artificial Neural network - apply gradient descent\n",
    "5. Dradient-descent - very imp, most of the algo are use gradient descent\n",
    "\n",
    "#### no need standardization - dicisionTree, randomforest, gradientboost, xdboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2829f",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "- normalization is the technique often applied  as part of data preparation for machine learning. the goal of normalization is to change the values of numeric columns in the dataset to use a common scale. without distoring difference in the ranges of values or losing information\n",
    "\n",
    "- just eliminet the unit just use magnitude - ex. weight has unit and magnitude keep value and eliminate units\n",
    "\n",
    "### Types of Normalization\n",
    "- Min-max scaling\n",
    "- mean normalization\n",
    "- max absolute scaling\n",
    "- roburst scaling\n",
    "\n",
    "#### when you apply normalization most of the time use min-max scaling\n",
    "--min - max scaling\n",
    "ex. weight - 130,67,81,45,90,106,32\n",
    "- farmula - value - min/max-min = 130-32/130-32,     67-32/130-32\n",
    "\n",
    "--- mean normalization\n",
    "- farmula --> value - mean/max-min  -- range[-1,1] , use for centered data\n",
    "\n",
    "--- max absolute value\n",
    "- farmula --> original value/ abs(max)  usecase - when sparse data most zeros\n",
    "\n",
    "--- roburst scaling\n",
    "- farmula --> value - median / IQR    (iqr = Q3 - Q1 ) , usecase = when u have lot of outliers in data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3d223",
   "metadata": {},
   "source": [
    "### Standardization vs Normalization\n",
    "- first ask question is feature scaling required?\n",
    "- ans - desicion tree and random forest use then no need\n",
    "- is confirm scaling then which one use?\n",
    "- ans - most of the time standardization work and great result and normalization is use when u have know min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca509855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
